/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.iotdb.db.index.preprocess;

import java.io.ByteArrayOutputStream;
import java.io.IOException;
import java.nio.ByteBuffer;
import java.util.List;
import org.apache.iotdb.db.exception.index.IllegalIndexParamException;
import org.apache.iotdb.db.exception.index.IndexRuntimeException;
import org.apache.iotdb.db.index.algorithm.elb.ELBCountFixedFeatureExtractor;
import org.apache.iotdb.db.index.common.IndexUtils;
import org.apache.iotdb.db.rescon.TVListAllocator;
import org.apache.iotdb.db.utils.TestOnly;
import org.apache.iotdb.db.utils.datastructure.TVList;
import org.apache.iotdb.tsfile.exception.NotImplementedException;
import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;
import org.apache.iotdb.tsfile.read.common.BatchData;
import org.apache.iotdb.tsfile.read.filter.basic.Filter;
import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;

/**
 * For all indexes, the raw input sequence has to be pre-processed before it's organized by indexes.
 * In general, index structure needn't maintain all of original data, but only pointers to the
 * original data (e.g. The start time and the end time can uniquely determine a time sequence).<p>
 *
 * {@linkplain IndexFeatureExtractor} makes a time window slide over the time series by some rules and
 * obtain a list of subsequences. The time windows may be time-fixed (Euclidean distance),
 * count-fixed (Time Warping). It scans the sequence with a certain overlap step (a.k.a. the update
 * size).
 *
 * A time window may be aligned to equal interval or equal range, which is called "Aligned
 * Sequences."<p>
 *
 * Many indexes will further extract features of alignment sequences, such as PAA, SAX, FFT, etc.
 * <p>
 *
 * After preprocessing, the subsequence will have three-level features:
 * <ul>
 *   <li>L1: a triplet to identify a subsequence: {@code {StartTime, EndTime, Length}}</li>
 *   <li>L2: aligned sequence: {@code {a1, a2, ..., an}}</li>
 *   <li>L3: customized feature: {@code {C1, C2, ..., Cm}}</li>
 * </ul>
 */
public abstract class IndexFeatureExtractor {

  /**
   * In the BUILD and QUERY modes, the preprocessor works differently.  For example, {@linkplain
   * ELBCountFixedFeatureExtractor ELBCountFixedPreprocessor}
   * does not need to generate L3 feature in QUERY-Mode, and NoIndex does not need to generate L1
   * Identifier and L2 Aligned sequence in BUILD-Mode.
   *
   * The Default is BUILD-mode, i.e., inQueryMode=false
   */
  protected boolean inQueryMode = false;
  /**
   * the type of sliding window, see {@linkplain WindowType}
   */
  protected WindowType windowType;
  /**
   * the window range, it depends on the window type.
   */
  protected int windowRange;
  /**
   * the the offset between two adjacent subsequences (a.k.a. the update size), depending on the the
   * window type.
   */
  protected int slideStep;

  /**
   * The time series will be divided into multiple chunks, but the sliding window moves step by
   * step, so the window across the adjacent two chunks will be cut off.  In addition to the current
   * {@code srcData}, the preprocessor may also have "previous". As a result, the time range of some
   * slices generated by the preprocessor might be a little earlier than the range of {@code
   * srcData}.
   */
  protected TVList srcData;


  public IndexFeatureExtractor(TSDataType dataType, WindowType widthType, int windowRange,
      int slideStep) {
    this.srcData = TVListAllocator.getInstance().allocate(dataType);
    if (slideStep > windowRange) {
      throw new IllegalIndexParamException(
          "Sorry, We do not yet support the slide step larger than the window range. "
              + "It may miss the information of some data points");
    }
    this.windowRange = windowRange;
    this.windowType = widthType;
    this.slideStep = slideStep;
  }

  public void appendNewSrcData(TVList newData) {
    TVList.append(this.srcData, newData, 0, newData.size());
    initParams();
  }

  public void appendNewSrcData(BatchData newData) {
    TVList.appendAll(this.srcData, newData);
    initParams();
  }

  protected abstract void initParams();

  public void setInQueryMode(boolean inQueryMode) {
    this.inQueryMode = inQueryMode;
  }

  /**
   * clear data which has been processed
   */
  public void clearProcessedSrcData() {
    int idx = nextUnprocessedWindowStartIdx();
    if (idx > srcData.size()) {
      throw new IndexRuntimeException(
          String.format("idx %d > srcData.size %d", idx, srcData.size()));
    }
    TVList swap = TVListAllocator.getInstance().allocate(srcData.getDataType());
    TVList.append(swap, this.srcData, idx, srcData.size() - idx);
    TVListAllocator.getInstance().release(srcData);
    this.srcData = swap;
  }

//  public IndexPreprocessor(TVList tvList, WindowType widthType, int windowRange, int slideStep) {
//    if (tvList == null) {
//      throw new IndexRuntimeException("init tvList cannot be null!");
//    }
//    this.srcData = TVListAllocator.getInstance().allocate(tvList.getDataType());
//    appendSrcData(tvList);
//    this.windowRange = windowRange;
//    this.windowType = widthType;
//    this.slideStep = slideStep;
//    // An empty header for program simplicity
//  }


  public abstract boolean hasNext();

  /**
   * Returns true if the pre-processor has more elements. i.e., return true if {@link #processNext}
   * would process the next data item rather than throwing an exception.)
   *
   * If there are more sequences, most {@code currentStartTime} and {@code currentEndTime} to the
   * next one. Otherwise, don't change them.
   *
   * @return {@code true} if there are more elements to be processed.
   */
  public abstract boolean hasNext(Filter timeFilter);

  /**
   * Processed the next element.
   */
  public abstract void processNext();

  /**
   * TVList may have been flushed many times, return the current offset.
   *
   * @return the current offset.
   */
  public abstract int getCurrentChunkOffset();

  /**
   * In this chunk, how many points have been processed.
   */
  public abstract int getCurrentChunkSize();

  /**
   * get the latest N L1-identifiers, including the current one. The caller needs to release them
   * after use.
   */
  public abstract List<Identifier> getLatestN_L1_Identifiers(int latestN);

  public TVList get_L0_SourceData(long startTime, long endTime) {
    TVList res = TVListAllocator.getInstance().allocate(srcData.getDataType());
    int idx = 0;
    while (idx < srcData.size() && srcData.getTime(idx) < startTime) {
      idx++;
    }
    while (idx < srcData.size() && srcData.getTime(idx) <= endTime) {
      IndexUtils.putAnyValue(srcData, idx, res);
      idx++;
    }
    return res;
  }

  /**
   * get current L1 identifier. The caller needs to release them after use.
   */
  public Identifier getCurrent_L1_Identifier() {
    List<Identifier> res = getLatestN_L1_Identifiers(1);
    return res.isEmpty() ? null : res.get(0);
  }

  public List<Identifier> getAll_L1_Identifiers() {
    int chunkNum = getCurrentChunkSize();
    return getLatestN_L1_Identifiers(chunkNum);
  }

  /**
   * get the latest N of L2 aligned sequences, including the current one. The caller needs to
   * release them after use.
   */
  public abstract List<Object> getLatestN_L2_AlignedSequences(int latestN);

  /**
   * get current L2 aligned sequences. The caller needs to release them after use.
   */
  public Object getCurrent_L2_AlignedSequence() {
    List<Object> res = getLatestN_L2_AlignedSequences(1);
    return res.isEmpty() ? null : res.get(0);
  }

  /**
   * get the latest N of L3 Features.
   *
   * @throws NotImplementedException Not all preprocessors support L3 features.
   */
  public List<Object> getLatestN_L3_Features(int latestN) {
    throw new NotImplementedException("This preprocessor doesn't support L3 feature");
  }

  /**
   * get the current L3 Features.
   *
   * @throws NotImplementedException Not all preprocessors support L3 features.
   */
  public Object getCurrent_L3_Feature() {
    List<Object> res = getLatestN_L3_Features(1);
    return res.isEmpty() ? null : res.get(0);
  }

  public WindowType getWindowType() {
    return windowType;
  }

  public int getWindowRange() {
    return windowRange;
  }

  public int getSlideStep() {
    return slideStep;
  }

  public abstract long getChunkStartTime();

  public abstract long getChunkEndTime();


  /**
   * The time window type: time-fixed or count-fixed. It determines the meanings of following
   * fields: {@code windowRange}, {@code windowRange}, {@code slideStep}.<p>
   *
   * COUNT_FIXED: TIME_FIXED:
   *
   * <p>See also: Kanat et. al. General Incremental Sliding-Window Aggregation. VLDB 2015.
   */
  public enum WindowType {
    TIME_FIXED, COUNT_FIXED;

    public static WindowType getIndexType(String windowType) {
      String normalized = windowType.toUpperCase();
      switch (normalized) {
        case "TIME_FIXED":
          return TIME_FIXED;
        case "COUNT_FIXED":
          return COUNT_FIXED;
        default:
          throw new NotImplementedException("unsupported window type:" + windowType);
      }
    }
  }

  /**
   * Called when the memory reaches the threshold. This function should release all allocated array
   * list which increases with the number of processed data pairs.<p>
   *
   * Note that, after cleaning up all past store, the next {@linkplain #processNext()} will still
   * start from the current point.
   *
   * IndexPreprocessor releases {@code previous} but <tt>doesn't release {@code srcData}</tt> which
   * may be still usable for next chunks, it's an important difference from {@code releaseSrcData}.
   *
   * We do not call {@linkplain #clearProcessedSrcData} when triggering Sub-Flush, but use offset to
   * label how many point we have processed, because Sub-Flush may be triggered frequently when the
   * memory threshold is relatively small. If we use {@linkplain #clearProcessedSrcData}, we need to
   * move unprocessed data to position 0. The less data we flush each time, the more data we need to
   * move. Therefore, we only use appendSrcData when starting startFlushMemTable.
   */
  public abstract long clear();

  /**
   * Not that, this method will remove all data and feature. If this method is called, all other
   * methods will be invalid like {@linkplain #serializePrevious()} and {@linkplain #processNext()}
   */
  public void closeAndRelease() {
    clear();
    TVListAllocator.getInstance().release(srcData);
  }

  /**
   * return how much memory is increased for each point processed. It's an amortized estimation,
   * depending on {@code storeIdentifier}, {@code storeAlignedSequence} and {@code storeFeature}
   */
  public abstract int getAmortizedSize();

  /**
   * deserialize from the buffer, set the previous overlapped data
   */
  public void deserializePrevious(ByteBuffer byteBuffer) {
    if (byteBuffer == null) {
      return;
    }
    srcData.clear();
    TSDataType dataType = TSDataType.deserialize(ReadWriteIOUtils.readShort(byteBuffer));
    if (dataType != srcData.getDataType()) {
      throw new IndexRuntimeException(String.format("serialized dataType %s != srcData dataType %s",
          dataType, srcData.getDataType()));
    }
    int len = ReadWriteIOUtils.readInt(byteBuffer);
    for (int i = 0; i < len; i++) {
      long time = ReadWriteIOUtils.readLong(byteBuffer);
      switch (srcData.getDataType()) {
        case BOOLEAN:
          srcData.putBoolean(time, ReadWriteIOUtils.readBool(byteBuffer));
          break;
        case INT32:
          srcData.putInt(time, ReadWriteIOUtils.readInt(byteBuffer));
          break;
        case INT64:
          srcData.putLong(time, ReadWriteIOUtils.readLong(byteBuffer));
          break;
        case FLOAT:
          srcData.putFloat(time, ReadWriteIOUtils.readFloat(byteBuffer));
          break;
        case DOUBLE:
          srcData.putDouble(time, ReadWriteIOUtils.readDouble(byteBuffer));
          break;
        case TEXT:
          srcData.putBinary(time, ReadWriteIOUtils.readBinary(byteBuffer));
          break;
      }
    }
  }

  /**
   * serialize the previous overlapped data and output
   */
  public ByteBuffer serializePrevious() throws IOException {
    int idx = nextUnprocessedWindowStartIdx();
    if (idx > srcData.size()) {
      throw new IOException(String.format("idx %d > srcData.size %d", idx, srcData.size()));
    }
    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    ReadWriteIOUtils.write(srcData.getDataType().serialize(), baos);
    ReadWriteIOUtils.write(srcData.size() - idx, baos);
    for (int i = idx; i < srcData.size(); i++) {
      ReadWriteIOUtils.write(srcData.getTime(i), baos);
      switch (srcData.getDataType()) {
        case BOOLEAN:
          ReadWriteIOUtils.write(srcData.getBoolean(i), baos);
          break;
        case INT32:
          ReadWriteIOUtils.write(srcData.getInt(i), baos);
          break;
        case INT64:
          ReadWriteIOUtils.write(srcData.getLong(i), baos);
          break;
        case FLOAT:
          ReadWriteIOUtils.write(srcData.getFloat(i), baos);
          break;
        case DOUBLE:
          ReadWriteIOUtils.write(srcData.getDouble(i), baos);
          break;
        case TEXT:
          ReadWriteIOUtils.write(srcData.getBinary(i), baos);
          break;
      }
    }
    byte[] array = baos.toByteArray();
    ByteBuffer byteBuffer = ByteBuffer.allocate(array.length);
    byteBuffer.put(array);
    byteBuffer.flip();
    return byteBuffer;
  }


  /**
   * After a calling of {@linkplain #processNext()}, currentStartTime and currentStartIdx has been
   * updated. This method is to calculate the start idx of the next window
   */
  public abstract int nextUnprocessedWindowStartIdx();


  @TestOnly
  public TVList getSrcData() {
    return srcData;
  }

}
